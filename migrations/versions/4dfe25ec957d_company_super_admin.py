"""company + super_admin

Revision ID: 4dfe25ec957d
Revises: f1257fd54d53
Create Date: 2025-06-15 00:49:55.794402

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision: str = '4dfe25ec957d'
down_revision: Union[str, None] = 'f1257fd54d53'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    
    # Create the company table first
    op.create_table('company',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('name', sa.String(length=100), nullable=False),
    sa.Column('slug', sa.String(length=60), nullable=False),
    sa.Column('is_active', sa.Boolean(), nullable=False),
    sa.Column('created_at', sa.DateTime(), nullable=False),
    sa.Column('updated_at', sa.DateTime(), nullable=False),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('name'),
    sa.UniqueConstraint('slug')
    )
    
    # Use batch mode for SQLite compatibility when adding foreign keys
    with op.batch_alter_table('data_point', schema=None) as batch_op:
        batch_op.add_column(sa.Column('company_id', sa.Integer(), nullable=True))
        batch_op.create_foreign_key('fk_data_point_company', 'company', ['company_id'], ['id'])
    
    with op.batch_alter_table('data_point_assignments', schema=None) as batch_op:
        batch_op.add_column(sa.Column('company_id', sa.Integer(), nullable=True))
        batch_op.create_index('idx_assignment_company', ['company_id'], unique=False)
        batch_op.create_foreign_key('fk_data_point_assignments_company', 'company', ['company_id'], ['id'])
    
    with op.batch_alter_table('entity', schema=None) as batch_op:
        batch_op.add_column(sa.Column('company_id', sa.Integer(), nullable=True))
        batch_op.create_foreign_key('fk_entity_company', 'company', ['company_id'], ['id'])
    
    with op.batch_alter_table('esg_data', schema=None) as batch_op:
        batch_op.add_column(sa.Column('company_id', sa.Integer(), nullable=True))
        batch_op.create_index('idx_esg_company', ['company_id'], unique=False)
        batch_op.create_foreign_key('fk_esg_data_company', 'company', ['company_id'], ['id'])
    
    # User table: company_id is intentionally nullable for SUPER_ADMIN users
    with op.batch_alter_table('user', schema=None) as batch_op:
        batch_op.add_column(sa.Column('company_id', sa.Integer(), nullable=True))
        batch_op.alter_column('role',
                   existing_type=sa.VARCHAR(length=10),
                   type_=sa.Enum('SUPER_ADMIN', 'ADMIN', 'USER', name='user_role'),
                   existing_nullable=False)
        batch_op.create_foreign_key('fk_user_company', 'company', ['company_id'], ['id'])
    
    # Note: In a future migration (after T-3 seed data), we can make company_id
    # non-nullable for data_point, data_point_assignments, entity, and esg_data
    # once proper company data is seeded
    
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table('user', schema=None) as batch_op:
        batch_op.drop_constraint('fk_user_company', type_='foreignkey')
        batch_op.alter_column('role',
                   existing_type=sa.Enum('SUPER_ADMIN', 'ADMIN', 'USER', name='user_role'),
                   type_=sa.VARCHAR(length=10),
                   existing_nullable=False)
        batch_op.drop_column('company_id')
    
    with op.batch_alter_table('esg_data', schema=None) as batch_op:
        batch_op.drop_constraint('fk_esg_data_company', type_='foreignkey')
        batch_op.drop_index('idx_esg_company')
        batch_op.drop_column('company_id')
    
    with op.batch_alter_table('entity', schema=None) as batch_op:
        batch_op.drop_constraint('fk_entity_company', type_='foreignkey')
        batch_op.drop_column('company_id')
    
    with op.batch_alter_table('data_point_assignments', schema=None) as batch_op:
        batch_op.drop_constraint('fk_data_point_assignments_company', type_='foreignkey')
        batch_op.drop_index('idx_assignment_company')
        batch_op.drop_column('company_id')
    
    with op.batch_alter_table('data_point', schema=None) as batch_op:
        batch_op.drop_constraint('fk_data_point_company', type_='foreignkey')
        batch_op.drop_column('company_id')
    
    op.drop_table('company')
    # ### end Alembic commands ###
